"""YOLOv11 + DINOv2 í…ŒìŠ¤íŠ¸ íŒŒì´í”„ë¼ì¸"""

import argparse
import torch
import torch.nn as nn
from ultralytics import YOLO
from torchvision import transforms
from PIL import Image
import yaml
import os
import cv2
import numpy as np
from pathlib import Path
from datetime import datetime
import json
from tqdm import tqdm
import matplotlib.pyplot as plt
import seaborn as sns
from math import cos, sin
import math


def compute_rotated_box_corners(cx, cy, w, h, angle):
    """íšŒì „ëœ ë°•ìŠ¤ì˜ 4ê°œ ëª¨ì„œë¦¬ ì¢Œí‘œ ê³„ì‚°"""
    dx = w / 2.0
    dy = h / 2.0
    
    local_corners = [
        (-dx, -dy), (dx, -dy), (dx, dy), (-dx, dy)
    ]
    
    c = cos(angle)
    s = sin(angle)
    
    corners = []
    for lx, ly in local_corners:
        rx = c * lx - s * ly + cx
        ry = s * lx + c * ly + cy
        corners.append((rx, ry))
    
    return corners


def correct_orientation_constrained(w, h, angle):
    """
    [ì‚¬ìš©ì ì§€ì • ë¡œì§] í˜•ìƒ ì ì‘í˜• ë³´ì • (Shape-Adaptive)
    ì¡°ê±´: ê°ì²´ëŠ” ì›ë˜ ë°©í–¥(ê°€ë¡œ/ì„¸ë¡œ)ì—ì„œ +-45ë„ ì´ë‚´ë¡œë§Œ ê¸°ìš¸ì–´ì§.
    ëª©í‘œ: 
      1. w >= h (ê°€ë¡œ ê°ì²´) -> ê°ë„ë¥¼ ì˜¤ë¥¸ìª½(-45~+45ë„)ìœ¼ë¡œ ë§ì¶¤
      2. h > w (ì„¸ë¡œ ê°ì²´) -> ê°ë„ë¥¼ ìœ„ìª½(-135~-45ë„)ìœ¼ë¡œ ë§ì¶¤
    """
    pi = math.pi
    
    # 1. ê°ë„ 1ì°¨ ì •ê·œí™” (-pi ~ +pi)
    angle = (angle + pi) % (2 * pi) - pi
    
    # 2. ê°ì²´ í˜•íƒœì— ë”°ë¥¸ ë°©í–¥ ë³´ì •
    if w >= h:
        # [Case A] ê°€ë¡œê°€ ê¸´ ê°ì²´ (Horizontal)
        # ëª©í‘œ: ê°ë„ê°€ 0ë„(ì˜¤ë¥¸ìª½) ê·¼ì²˜ì—¬ì•¼ í•¨.
        # ë§Œì•½ ê°ë„ê°€ ì ˆëŒ€ê°’ 90ë„(pi/2)ë¥¼ ë„˜ì–´ê°€ë©´ 'ì™¼ìª½'ì„ ë³´ê³  ìˆë‹¤ëŠ” ëœ»ì´ë¯€ë¡œ ë’¤ì§‘ìŒ.
        if abs(angle) > pi / 2:
            angle -= pi  # 180ë„ íšŒì „
            
    else:
        # [Case B] ì„¸ë¡œê°€ ê¸´ ê°ì²´ (Vertical)
        # ëª©í‘œ: ê°ë„ê°€ -90ë„(ìœ„ìª½) ê·¼ì²˜ì—¬ì•¼ í•¨. (OpenCV ì¢Œí‘œê³„: -90ë„ê°€ 12ì‹œ ë°©í–¥)
        
        # ê°„ë‹¨í•˜ê²Œ: "Yì¶• ì•„ë˜(ì–‘ìˆ˜ ê°ë„)"ë¥¼ ë³´ê³  ìˆìœ¼ë©´ ë¬´ì¡°ê±´ ìœ„ë¡œ ì˜¬ë¦¼
        if angle > 0:  
            angle -= pi
        
        # -180ë„ ê·¼ì²˜(-pi)ì¸ ê²½ìš°ë„ ì•„ë˜ìª½(6ì‹œ)ì— ê°€ê¹Œìš°ë¯€ë¡œ ìœ„ë¡œ ë³´ëƒ„
        # (ë‹¨, +-45ë„ ì œí•œ ì¡°ê±´ ë•Œë¬¸ì— ì´ ì¼€ì´ìŠ¤ëŠ” ë“œë¬¼ê² ì§€ë§Œ ì•ˆì „ì¥ì¹˜)
        if angle < -pi + (pi/4): # -135ë„ë³´ë‹¤ ë” ì‘ìœ¼ë©´ (ì˜ˆ: -170ë„)
             angle += pi

    # ìµœì¢… ê°ë„ ì¬ì •ê·œí™”
    angle = (angle + pi) % (2 * pi) - pi
            
    return w, h, angle


def correct_orientation_door(w, h, angle, part):
    """
    ë„ì–´ ëª¨ë“œ ì „ìš© ë°©í–¥ ë³´ì •
    - ìƒë‹¨ë¶€(high)ì™€ í•˜ë‹¨ë¶€(low): ë¬´ì¡°ê±´ ì„¸ë¡œ (h > wë¡œ ê°•ì œ), ëª©í‘œ ê°ë„ -90ë„
    - ì¤‘ë‹¨ë¶€(mid): ë¬´ì¡°ê±´ ê°€ë¡œ (w > hë¡œ ê°•ì œ), ëª©í‘œ ê°ë„ 0ë„
    - ëª¨ë“  ë¶€ìœ„: ì ˆëŒ“ê°’ì´ ì‘ì€ ìª½ìœ¼ë¡œ íšŒì „ (0ì— ê°€ê¹Œìš´ ìª½)
    
    Args:
        w, h: ë„ˆë¹„, ë†’ì´
        angle: íšŒì „ ê°ë„ (ë¼ë””ì•ˆ)
        part: 'high', 'mid', 'low'
    
    Returns:
        w, h, angle: ë³´ì •ëœ ë„ˆë¹„, ë†’ì´, ê°ë„
    """
    pi = math.pi
    
    # 1. ê°ë„ ì •ê·œí™” (-pi ~ +pi)
    angle = (angle + pi) % (2 * pi) - pi
    
    # 2. ë¶€ìœ„ë³„ ê°•ì œ ë°©í–¥ ì ìš©
    if part in ['high', 'low']:
        # ìƒë‹¨ë¶€/í•˜ë‹¨ë¶€: ë¬´ì¡°ê±´ ì„¸ë¡œ (h > w)
        if w > h:
            w, h = h, w  # wì™€ h êµí™˜
            angle += pi / 2  # 90ë„ íšŒì „
        
        # ëª©í‘œ ê°ë„: -90ë„ (ìœ„ìª½)
        target_angle = -pi / 2
        
        # ì ˆëŒ“ê°’ì´ ì‘ì€ ìª½ìœ¼ë¡œ íšŒì „ (0ì— ê°€ê¹Œìš´ ìª½)
        # í˜„ì¬ ê°ë„ì™€ ëª©í‘œ ê°ë„ì˜ ì°¨ì´ë¥¼ ê³„ì‚°
        diff = angle - target_angle
        
        # -180~180 ë²”ìœ„ë¡œ ì •ê·œí™”
        diff = (diff + pi) % (2 * pi) - pi
        
        # ì ˆëŒ“ê°’ì´ 90ë„(pi/2)ë³´ë‹¤ í¬ë©´ ë°˜ëŒ€ ë°©í–¥ìœ¼ë¡œ íšŒì „
        # ì˜ˆ: diffê°€ 150ë„ë©´ -30ë„ë¡œ, -150ë„ë©´ 30ë„ë¡œ
        if abs(diff) > pi / 2:
            diff = diff - pi if diff > 0 else diff + pi
        
        angle = target_angle + diff
        
    elif part == 'mid':
        # ì¤‘ë‹¨ë¶€: ë¬´ì¡°ê±´ ê°€ë¡œ (w > h)
        if h > w:
            w, h = h, w  # wì™€ h êµí™˜
            angle += pi / 2  # 90ë„ íšŒì „
        
        # ëª©í‘œ ê°ë„: 0ë„ (ì˜¤ë¥¸ìª½)
        target_angle = 0.0
        
        # ì ˆëŒ“ê°’ì´ ì‘ì€ ìª½ìœ¼ë¡œ íšŒì „ (0ì— ê°€ê¹Œìš´ ìª½)
        # í˜„ì¬ ê°ë„ì™€ ëª©í‘œ ê°ë„ì˜ ì°¨ì´ë¥¼ ê³„ì‚°
        diff = angle - target_angle
        
        # -180~180 ë²”ìœ„ë¡œ ì •ê·œí™”
        diff = (diff + pi) % (2 * pi) - pi
        
        # ì ˆëŒ“ê°’ì´ 90ë„(pi/2)ë³´ë‹¤ í¬ë©´ ë°˜ëŒ€ ë°©í–¥ìœ¼ë¡œ íšŒì „
        # ì˜ˆ: diffê°€ 150ë„ë©´ -30ë„ë¡œ, -150ë„ë©´ 30ë„ë¡œ
        if abs(diff) > pi / 2:
            diff = diff - pi if diff > 0 else diff + pi
        
        angle = target_angle + diff
    
    # ìµœì¢… ê°ë„ ì¬ì •ê·œí™”
    angle = (angle + pi) % (2 * pi) - pi
    
    return w, h, angle


def point_in_rotated_box(px, py, box_cx, box_cy, box_w, box_h, box_angle):
    """
    ì ì´ íšŒì „ëœ ë°•ìŠ¤ ë‚´ë¶€ì— ìˆëŠ”ì§€ í™•ì¸
    
    Args:
        px, py: í™•ì¸í•  ì ì˜ ì¢Œí‘œ
        box_cx, box_cy: ë°•ìŠ¤ ì¤‘ì‹¬ì 
        box_w, box_h: ë°•ìŠ¤ ë„ˆë¹„, ë†’ì´
        box_angle: ë°•ìŠ¤ íšŒì „ ê°ë„ (ë¼ë””ì•ˆ)
    
    Returns:
        bool: ì ì´ ë°•ìŠ¤ ë‚´ë¶€ì— ìˆìœ¼ë©´ True
    """
    # ì ì„ ë°•ìŠ¤ ì¤‘ì‹¬ ê¸°ì¤€ìœ¼ë¡œ ì´ë™
    dx = px - box_cx
    dy = py - box_cy
    
    # íšŒì „ ê°ë„ì˜ ì—­ë³€í™˜ (ë°•ìŠ¤ ì¢Œí‘œê³„ë¡œ ë³€í™˜)
    c = cos(-box_angle)
    s = sin(-box_angle)
    
    # íšŒì „ëœ ì¢Œí‘œ
    local_x = c * dx - s * dy
    local_y = s * dx + c * dy
    
    # ë°•ìŠ¤ ë‚´ë¶€ì¸ì§€ í™•ì¸
    return abs(local_x) <= box_w / 2 and abs(local_y) <= box_h / 2


def crop_rotated_object(img, cx, cy, w, h, angle, part=None):
    """
    íšŒì „ëœ ê°ì²´ë¥¼ crop
    
    Args:
        img: ì´ë¯¸ì§€
        cx, cy: ì¤‘ì‹¬ì 
        w, h: ë„ˆë¹„, ë†’ì´
        angle: íšŒì „ ê°ë„ (ë¼ë””ì•ˆ)
        part: ë¶€ìœ„ ('high', 'mid', 'low') - ë„ì–´ ëª¨ë“œì¼ ë•Œë§Œ ì‚¬ìš©
    """
    img_h, img_w = img.shape[:2]

    # ë°©í–¥ ë³´ì •
    if part is not None and part in ['high', 'mid', 'low']:
        # ë„ì–´ ëª¨ë“œ: ë¶€ìœ„ë³„ ê°•ì œ ë°©í–¥ ì ìš©
        w, h, angle = correct_orientation_door(w, h, angle, part)
    else:
        # ì¼ë°˜ ëª¨ë“œ: ê¸°ì¡´ ë¡œì§ ì‚¬ìš©
        w, h, angle = correct_orientation_constrained(w, h, angle)
    
    # ê°ë„ê°€ 0ì— ë§¤ìš° ê°€ê¹Œìš°ë©´ ì¼ë°˜ crop
    if abs(angle) < 1e-6:
        x1 = max(0, int(cx - w / 2))
        y1 = max(0, int(cy - h / 2))
        x2 = min(img_w, int(cx + w / 2))
        y2 = min(img_h, int(cy + h / 2))
        
        if x1 >= x2 or y1 >= y2:
            return None
        
        crop = img[y1:y2, x1:x2]
        crop_resized = cv2.resize(crop, (int(w), int(h)), interpolation=cv2.INTER_LINEAR)
        return crop_resized
    
    src_corners = compute_rotated_box_corners(cx, cy, w, h, angle)
    src_points = np.array(src_corners, dtype=np.float32)
    
    dst_corners = [
        (0, 0), (w, 0), (w, h), (0, h)
    ]
    dst_points = np.array(dst_corners, dtype=np.float32)
    
    M = cv2.getPerspectiveTransform(src_points, dst_points)
    
    warped = cv2.warpPerspective(img, M, (int(w), int(h)), 
                                  flags=cv2.INTER_LINEAR,
                                  borderMode=cv2.BORDER_CONSTANT,
                                  borderValue=(0, 0, 0))
    return warped


class DINOv2Classifier(nn.Module):
    """DINOv2 ë¶„ë¥˜ ëª¨ë¸ (ì²´í¬í¬ì¸íŠ¸ ë¡œë”©ìš©)"""
    def __init__(self, backbone, embed_dim, num_classes=2):
        super().__init__()
        self.backbone = backbone
        self.classifier = nn.Sequential(
            nn.Linear(embed_dim, 512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, num_classes)
        )
    
    def forward(self, x):
        features = self.backbone(x)
        return self.classifier(features)


class YOLODINOPipeline:
    def __init__(self, mode='frontdoor', yolo_model_path=None, 
                 dino_models=None, device='cuda', conf_threshold=0.25,
                 voting_method='hard', project_name='pipeline_test', use_obb=False):
        """
        YOLO + DINOv2 í…ŒìŠ¤íŠ¸ íŒŒì´í”„ë¼ì¸
        
        Args:
            mode (str): 'frontdoor' ë˜ëŠ” 'bolt'
            yolo_model_path (str): YOLO ëª¨ë¸ ê²½ë¡œ
            dino_models (dict): DINOv2 ëª¨ë¸ ê²½ë¡œë“¤
                - frontdoor: {'high': path, 'mid': path, 'low': path}
                - bolt: {'bolt': path}
            device (str): ë””ë°”ì´ìŠ¤
            conf_threshold (float): YOLO ì‹ ë¢°ë„ ì„ê³„ê°’
            voting_method (str): 'hard' ë˜ëŠ” 'soft' (frontdoorìš©)
            project_name (str): í”„ë¡œì íŠ¸ ì´ë¦„ (ê²°ê³¼ í´ë”ëª…ì— ì‚¬ìš©)
            use_obb (bool): OBB(Oriented Bounding Box) ëª¨ë“œ ì‚¬ìš© ì—¬ë¶€
        """
        self.mode = mode.lower()
        # 'door'ë¥¼ 'frontdoor'ë¡œ ì •ê·œí™”
        if self.mode == 'door':
            self.mode = 'frontdoor'
        
        self.device = device if torch.cuda.is_available() else 'cpu'
        self.conf_threshold = conf_threshold
        self.voting_method = voting_method
        self.project_name = project_name
        self.use_obb = use_obb
        
        # YOLO ëª¨ë¸ ë¡œë“œ
        if yolo_model_path is None:
            raise ValueError("YOLO ëª¨ë¸ ê²½ë¡œë¥¼ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.")
        print(f"ğŸ”„ YOLO ëª¨ë¸ ë¡œë“œ ì¤‘: {yolo_model_path}")
        self.yolo_model = YOLO(yolo_model_path)
        
        # DINOv2 ëª¨ë¸ ë¡œë“œ
        self.dino_models = {}
        self.dino_num_classes = {}  # ê° ëª¨ë¸ì˜ í´ë˜ìŠ¤ ìˆ˜ ì €ì¥
        if dino_models is None:
            raise ValueError("DINOv2 ëª¨ë¸ ê²½ë¡œë¥¼ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.")
        
        if self.mode == 'frontdoor':
            required_keys = ['high', 'mid', 'low']
            for key in required_keys:
                if key not in dino_models:
                    raise ValueError(f"frontdoor ëª¨ë“œëŠ” {required_keys} ëª¨ë¸ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            
            for part, model_path in dino_models.items():
                print(f"ğŸ”„ DINOv2 ëª¨ë¸ ë¡œë“œ ì¤‘ ({part}): {model_path}")
                model, num_classes = self._load_dino_model(model_path)
                self.dino_models[part] = model
                self.dino_num_classes[part] = num_classes
        
        elif self.mode == 'bolt':
            if 'bolt' not in dino_models:
                raise ValueError("bolt ëª¨ë“œëŠ” 'bolt' ëª¨ë¸ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            print(f"ğŸ”„ DINOv2 ëª¨ë¸ ë¡œë“œ ì¤‘ (bolt): {dino_models['bolt']}")
            model, num_classes = self._load_dino_model(dino_models['bolt'])
            self.dino_models['bolt'] = model
            self.dino_num_classes['bolt'] = num_classes
        
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë“œ: {self.mode}")
        
        # YOLO í´ë˜ìŠ¤ ë§¤í•‘ (bolt ëª¨ë“œìš©)
        self.bolt_class_names = {
            0: 'bolt_frontside',
            1: 'bolt_side',
            2: 'sedan (trunklid)',
            3: 'suv (trunklid)',
            4: 'hood',
            5: 'long (frontfender)',
            6: 'mid (frontfender)',
            7: 'short (frontfender)'
        }
        
        # DINOv2 ì „ì²˜ë¦¬
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])
        
        print(f"âœ“ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"  - ëª¨ë“œ: {self.mode}")
        print(f"  - ë””ë°”ì´ìŠ¤: {self.device}")
        print(f"  - YOLO ì‹ ë¢°ë„ ì„ê³„ê°’: {self.conf_threshold}")
        print(f"  - OBB ëª¨ë“œ: {self.use_obb}")
        if self.mode == 'frontdoor':
            print(f"  - Voting ë°©ë²•: {self.voting_method}")
            # ê° ë¶€ìœ„ë³„ í´ë˜ìŠ¤ ìˆ˜ ì¶œë ¥
            for part in ['high', 'mid', 'low']:
                if part in self.dino_num_classes:
                    num_cls = self.dino_num_classes[part]
                    if num_cls == 5:
                        mode_text = "5-class"
                    elif num_cls == 4:
                        mode_text = "4-class"
                    else:
                        mode_text = "2-class (simple)"
                    print(f"  - DINO {part}: {mode_text}")
        else:  # bolt
            print(f"  - Voting ë°©ë²•: {self.voting_method}")
            num_cls = self.dino_num_classes.get('bolt', 2)
            mode_text = "4-class" if num_cls == 4 else "2-class (simple)"
            print(f"  - DINO bolt: {mode_text}")
    
    def _load_dino_model(self, model_path):
        """DINOv2 ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ"""
        checkpoint = torch.load(model_path, map_location=self.device)
        config = checkpoint.get('config', {})
        
        model_size = config.get('model_size', 'small')
        num_classes = config.get('num_classes', 2)
        
        # ë°±ë³¸ ë¡œë“œ
        model_map = {
            'small': ('dinov2_vits14', 384),
            'base': ('dinov2_vitb14', 768),
            'large': ('dinov2_vitl14', 1024),
            'giant': ('dinov2_vitg14', 1536)
        }
        model_name, embed_dim = model_map.get(model_size, ('dinov2_vits14', 384))
        
        backbone = torch.hub.load('facebookresearch/dinov2', model_name)
        model = DINOv2Classifier(backbone, embed_dim, num_classes)
        model.load_state_dict(checkpoint['model_state_dict'])
        model.to(self.device)
        model.eval()
        
        return model, num_classes
    
    def _extract_gt_label(self, img_path):
        """
        ì´ë¯¸ì§€ ê²½ë¡œì—ì„œ GT ë¼ë²¨ ì¶”ì¶œ
        ê²½ë¡œì— 'bad' ë˜ëŠ” 'defect'ê°€ ìˆìœ¼ë©´ ë¶ˆëŸ‰(1), 'good'ì´ ìˆìœ¼ë©´ ì–‘í’ˆ(0)
        """
        path_lower = img_path.lower()
        
        # ê²½ë¡œë¥¼ '/'ë¡œ ë¶„í• í•˜ì—¬ í´ë”ëª… í™•ì¸
        parts = path_lower.split('/')
        
        if 'bad' in parts or 'defect' in parts:
            return 1  # ë¶ˆëŸ‰
        elif 'good' in parts:
            return 0  # ì–‘í’ˆ
        else:
            # íŒŒì¼ëª…ì—ì„œë„ í™•ì¸
            filename = os.path.basename(path_lower)
            if 'bad' in filename or 'defect' in filename:
                return 1
            elif 'good' in filename:
                return 0
            else:
                return None  # GTë¥¼ ì•Œ ìˆ˜ ì—†ìŒ
    
    def process_image_list(self, txt_file):
        """
        ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬
        
        Args:
            txt_file (str): ì´ë¯¸ì§€ ê²½ë¡œê°€ ë‹´ê¸´ txt íŒŒì¼
        """
        # ê²°ê³¼ í´ë” ìƒì„±
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        result_dir = Path('runs') / f"{self.project_name}_{timestamp}"
        result_dir.mkdir(parents=True, exist_ok=True)
        
        # í•˜ìœ„ í´ë” ìƒì„±
        crops_dir = result_dir / 'crops'
        vis_dir = result_dir / 'visualizations'
        crops_dir.mkdir(exist_ok=True)
        vis_dir.mkdir(exist_ok=True)
        
        # ì´ë¯¸ì§€ ê²½ë¡œ ì½ê¸°
        with open(txt_file, 'r') as f:
            image_paths = [line.strip() for line in f if line.strip()]
        
        print(f"\n{'='*60}")
        print(f"ğŸš€ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘")
        print(f"{'='*60}")
        print(f"  - ì´ ì´ë¯¸ì§€ ìˆ˜: {len(image_paths)}")
        print(f"  - ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {result_dir}\n")
        
        results = []
        y_true = []
        y_pred = []
        
        for idx, img_path in enumerate(tqdm(image_paths, desc="Processing")):
            if not os.path.exists(img_path):
                print(f"âš ï¸  ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {img_path}")
                continue
            
            # GT ë¼ë²¨ ì¶”ì¶œ
            gt_label = self._extract_gt_label(img_path)
            
            # ì´ë¯¸ì§€ ì²˜ë¦¬
            result = self.process_single_image(
                img_path, 
                result_dir, 
                crops_dir, 
                vis_dir, 
                idx,
                gt_label
            )
            results.append(result)
            
            # confusion matrixìš© ë°ì´í„° ìˆ˜ì§‘
            if gt_label is not None and result['status'] in ['processed', 'defect']:
                y_true.append(gt_label)
                pred_label = 1 if result['final_prediction'] == 'defect' else 0
                y_pred.append(pred_label)
                
                # ë³¼íŠ¸ ëª¨ë“œì´ê³  4-classì¸ ê²½ìš°, ê° ë³¼íŠ¸ì˜ í´ë˜ìŠ¤ ì˜ˆì¸¡ë„ ì €ì¥
                if self.mode == 'bolt' and result.get('bolt_results'):
                    # ì²« ë²ˆì§¸ ë³¼íŠ¸ ê²°ê³¼ì—ì„œ num_classes í™•ì¸
                    first_bolt = result['bolt_results'][0] if result['bolt_results'] else None
                    if first_bolt and first_bolt.get('num_classes') == 4:
                        # ì›ë³¸ í´ë˜ìŠ¤ ì˜ˆì¸¡ ì €ì¥ (ë‚˜ì¤‘ì— confusion matrix ìƒì„±ìš©)
                        if not hasattr(self, 'bolt_y_true_class'):
                            self.bolt_y_true_class = []
                            self.bolt_y_pred_class = []
                        
                        # GTëŠ” 0/1ë§Œ ìˆìœ¼ë¯€ë¡œ, 4-class confusion matrixëŠ” ì œí•œì 
                        # GTê°€ 0ì´ë©´ í´ë˜ìŠ¤ 0, GTê°€ 1ì´ë©´ ì²« ë²ˆì§¸ ë³¼íŠ¸ì˜ ì˜ˆì¸¡ í´ë˜ìŠ¤ ì‚¬ìš©
                        if gt_label == 0:
                            gt_class = 0  # ì–‘í’ˆ
                        else:
                            # ë¶ˆëŸ‰ì¸ ê²½ìš°, ì²« ë²ˆì§¸ ë³¼íŠ¸ì˜ ì˜ˆì¸¡ í´ë˜ìŠ¤ ì‚¬ìš© (1,2,3 ì¤‘ í•˜ë‚˜)
                            pred_class_val = first_bolt['pred_class']
                            gt_class = pred_class_val if pred_class_val != 0 else 1
                        
                        pred_class = first_bolt['pred_class']
                        self.bolt_y_true_class.append(gt_class)
                        self.bolt_y_pred_class.append(pred_class)
                
                # ë„ì–´ ëª¨ë“œì´ê³  5-classì¸ ê²½ìš°, ê° ë¶€ìœ„ì˜ í´ë˜ìŠ¤ ì˜ˆì¸¡ë„ ì €ì¥
                if self.mode == 'frontdoor' and result.get('parts'):
                    # ì²« ë²ˆì§¸ ë¶€ìœ„ ê²°ê³¼ì—ì„œ num_classes í™•ì¸
                    first_part_key = list(result['parts'].keys())[0] if result['parts'] else None
                    if first_part_key:
                        first_part = result['parts'][first_part_key]
                        if first_part and first_part.get('num_classes') == 5:
                            # ì›ë³¸ í´ë˜ìŠ¤ ì˜ˆì¸¡ ì €ì¥ (ë‚˜ì¤‘ì— confusion matrix ìƒì„±ìš©)
                            if not hasattr(self, 'door_y_true_class'):
                                self.door_y_true_class = []
                                self.door_y_pred_class = []
                            
                            # GTëŠ” 0/1ë§Œ ìˆìœ¼ë¯€ë¡œ, 5-class confusion matrixëŠ” ì œí•œì 
                            # GTê°€ 0ì´ë©´ í´ë˜ìŠ¤ 0, GTê°€ 1ì´ë©´ ì²« ë²ˆì§¸ ë¶€ìœ„ì˜ ì˜ˆì¸¡ í´ë˜ìŠ¤ ì‚¬ìš©
                            if gt_label == 0:
                                gt_class = 0  # ì–‘í’ˆ
                            else:
                                # ë¶ˆëŸ‰ì¸ ê²½ìš°, ì²« ë²ˆì§¸ ë¶€ìœ„ì˜ ì˜ˆì¸¡ í´ë˜ìŠ¤ ì‚¬ìš© (1,2,3,4 ì¤‘ í•˜ë‚˜)
                                pred_class_val = first_part['pred_class']
                                gt_class = pred_class_val if pred_class_val != 0 else 1
                            
                            pred_class = first_part['pred_class']
                            self.door_y_true_class.append(gt_class)
                            self.door_y_pred_class.append(pred_class)
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬ (ë§¤ 10ê°œ ì´ë¯¸ì§€ë§ˆë‹¤)
            if (idx + 1) % 10 == 0:
                import gc
                gc.collect()
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
        
        # ê²°ê³¼ ì €ì¥
        self._save_results(results, result_dir)
        
        # Confusion Matrix ìƒì„±
        if len(y_true) > 0:
            self._plot_confusion_matrix(y_true, y_pred, result_dir)
            
            # ë³¼íŠ¸ ëª¨ë“œì´ê³  4-classì¸ ê²½ìš°, í´ë˜ìŠ¤ë³„ confusion matrixë„ ìƒì„±
            if self.mode == 'bolt' and hasattr(self, 'bolt_y_true_class') and len(self.bolt_y_true_class) > 0:
                self._plot_bolt_class_confusion_matrix(self.bolt_y_true_class, self.bolt_y_pred_class, result_dir)
            
            # ë„ì–´ ëª¨ë“œì´ê³  5-classì¸ ê²½ìš°, í´ë˜ìŠ¤ë³„ confusion matrixë„ ìƒì„±
            if self.mode == 'frontdoor' and hasattr(self, 'door_y_true_class') and len(self.door_y_true_class) > 0:
                self._plot_door_class_confusion_matrix(self.door_y_true_class, self.door_y_pred_class, result_dir)
        
        # í†µê³„ ì¶œë ¥
        self._print_statistics(results, y_true, y_pred)
        
        return results
    
    def process_single_image(self, img_path, result_dir, crops_dir, vis_dir, idx, gt_label):
        """ë‹¨ì¼ ì´ë¯¸ì§€ ì²˜ë¦¬"""
        try:
            # ì´ë¯¸ì§€ ë¡œë“œ
            img = cv2.imread(img_path)
            if img is None:
                return {
                    'image_path': img_path,
                    'status': 'error',
                    'message': 'Failed to load image',
                    'gt_label': gt_label
                }
            
            # YOLO ê²€ì¶œ
            yolo_results = self.yolo_model.predict(
                img_path, 
                conf=self.conf_threshold,
                verbose=False
            )[0]
            
            if self.use_obb:
                # OBB ëª¨ë“œ
                obbs = yolo_results.obb if hasattr(yolo_results, 'obb') else None
                if obbs is None:
                    return {
                        'image_path': img_path,
                        'status': 'error',
                        'message': 'OBB ëª¨ë“œì¸ë° ëª¨ë¸ì´ OBBë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.',
                        'gt_label': gt_label
                    }
                
                # OBB ì†ì„± í™•ì¸ ë° ë””ë²„ê¹…
                try:
                    if len(obbs) > 0:
                        first_obb = obbs[0]
                        # xywhr ì†ì„±ì´ ìˆëŠ”ì§€ í™•ì¸
                        if not hasattr(first_obb, 'xywhr'):
                            return {
                                'image_path': img_path,
                                'status': 'error',
                                'message': f'OBB ê°ì²´ì— xywhr ì†ì„±ì´ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ì†ì„±: {dir(first_obb)}',
                                'gt_label': gt_label
                            }
                    
                    if self.mode == 'frontdoor':
                        result = self._process_frontdoor_obb(
                            img, img_path, obbs, crops_dir, vis_dir, idx, gt_label
                        )
                    elif self.mode == 'bolt':
                        result = self._process_bolt_obb(
                            img, img_path, obbs, crops_dir, vis_dir, idx, gt_label
                        )
                except Exception as e:
                    import traceback
                    return {
                        'image_path': img_path,
                        'status': 'error',
                        'message': f'OBB ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}',
                        'traceback': traceback.format_exc(),
                        'gt_label': gt_label
                    }
            else:
                # ì¼ë°˜ bbox ëª¨ë“œ
                boxes = yolo_results.boxes
                
                if self.mode == 'frontdoor':
                    result = self._process_frontdoor(
                        img, img_path, boxes, crops_dir, vis_dir, idx, gt_label
                    )
                elif self.mode == 'bolt':
                    result = self._process_bolt(
                        img, img_path, boxes, crops_dir, vis_dir, idx, gt_label
                    )
            
            result['gt_label'] = gt_label
            return result
        
        except Exception as e:
            import traceback
            return {
                'image_path': img_path,
                'status': 'error',
                'message': str(e),
                'traceback': traceback.format_exc(),
                'gt_label': gt_label
            }
    
    def _process_frontdoor(self, img, img_path, boxes, crops_dir, vis_dir, idx, gt_label):
        """í”„ë¡ íŠ¸ë„ì–´ ì²˜ë¦¬"""
        # í´ë˜ìŠ¤ë³„ ê²€ì¶œ ê²°ê³¼ ì •ë¦¬
        detections = {'high': [], 'mid': [], 'low': []}
        
        for box in boxes:
            cls_id = int(box.cls[0])
            conf = float(box.conf[0])
            xyxy = box.xyxy[0].cpu().numpy()
            
            class_name = self.yolo_model.names[cls_id].lower()
            if class_name in detections:
                detections[class_name].append({
                    'bbox': xyxy,
                    'conf': conf
                })
        
        # ì¡°ê±´ í™•ì¸: high/mid/low ê° 1ê°œì”© OR high/low ê° 1ê°œì”©
        has_all_three = (len(detections['high']) == 1 and 
                        len(detections['mid']) == 1 and 
                        len(detections['low']) == 1)
        has_high_low = (len(detections['high']) == 1 and 
                       len(detections['low']) == 1 and 
                       len(detections['mid']) == 0)
        
        if not (has_all_three or has_high_low):
            # ì‹œê°í™” (ê²€ì¶œ ì‹¤íŒ¨)
            self._save_visualization(
                img, img_path, [], vis_dir, idx, 
                'skipped', gt_label, None, None
            )
            return {
                'image_path': img_path,
                'status': 'skipped',
                'message': 'Detection condition not met',
                'detections': {k: len(v) for k, v in detections.items()}
            }
        
        # ê° ë¶€ìœ„ë³„ í¬ë¡­ ë° ë¶„ë¥˜
        part_results = {}
        parts_to_process = ['high', 'mid', 'low'] if has_all_three else ['high', 'low']
        crop_info = []
        
        for part in parts_to_process:
            if len(detections[part]) > 0:
                bbox = detections[part][0]['bbox']
                x1, y1, x2, y2 = map(int, bbox)
                cropped = img[y1:y2, x1:x2]
                
                # í¬ë¡­ ì´ë¯¸ì§€ ì €ì¥
                crop_filename = f"{idx:04d}_{part}.jpg"
                crop_path = crops_dir / crop_filename
                cv2.imwrite(str(crop_path), cropped)
                
                # DINOv2 ë¶„ë¥˜
                result = self._classify_with_dino(cropped, part)
                
                part_results[part] = {
                    'bbox': bbox.tolist(),
                    'yolo_conf': detections[part][0]['conf'],
                    'pred_class': result['pred_class'],
                    'confidence': result['confidence'],
                    'is_defect': result['is_defect'],
                    'defect_confidence': result['defect_confidence'],
                    'num_classes': result['num_classes'],
                    'crop_path': str(crop_path)
                }
                
                # ë¼ë²¨ ìƒì„±
                num_classes = result['num_classes']
                if num_classes == 5:
                    # 5-class ëª¨ë“œ (ë„ì–´): good, shipping_seal, no_seal, work_seal, tape_seal
                    class_names = ['good', 'shipping_seal', 'no_seal', 'work_seal', 'tape_seal']
                    class_name = class_names[result['pred_class']] if result['pred_class'] < len(class_names) else str(result['pred_class'])
                    label = f"{part}: {class_name} ({result['confidence'][result['pred_class']]:.2f})"
                elif num_classes == 4:
                    # 4-class ëª¨ë“œ (ë³¼íŠ¸): frontside_good, frontside_bad, side_good, side_bad
                    class_names = ['frontside_good', 'frontside_bad', 'side_good', 'side_bad']
                    class_name = class_names[result['pred_class']] if result['pred_class'] < len(class_names) else str(result['pred_class'])
                    label = f"{part}: {class_name} ({result['confidence'][result['pred_class']]:.2f})"
                else:
                    # 2-class ëª¨ë“œ
                    label = f"{part}: {'Bad' if result['is_defect'] else 'Good'} ({result['confidence'][result['pred_class']]:.2f})"
                
                crop_info.append({
                    'bbox': bbox,
                    'label': label,
                    'color': (0, 0, 255) if result['is_defect'] else (0, 255, 0)
                })
        
        # Voting
        if self.voting_method == 'hard':
            final_pred = self._hard_voting(part_results)
        else:  # soft
            final_pred = self._soft_voting(part_results)
        
        # ì‹œê°í™” ì €ì¥
        self._save_visualization(
            img, img_path, crop_info, vis_dir, idx, 
            final_pred, gt_label, part_results, None
        )
        
        return {
            'image_path': img_path,
            'status': 'processed',
            'mode': 'frontdoor',
            'parts': part_results,
            'final_prediction': final_pred,
            'voting_method': self.voting_method
        }
    
    def _process_bolt(self, img, img_path, boxes, crops_dir, vis_dir, idx, gt_label):
        """ë³¼íŠ¸ ì²˜ë¦¬"""
        # í´ë˜ìŠ¤ë³„ ê²€ì¶œ ê²°ê³¼ ì •ë¦¬
        bolt_detections = []  # 0, 1ë²ˆ í´ë˜ìŠ¤ (ë³¼íŠ¸)
        frame_detections = []  # 2~7ë²ˆ í´ë˜ìŠ¤ (í”„ë ˆì„)
        
        for box in boxes:
            cls_id = int(box.cls[0])
            conf = float(box.conf[0])
            xyxy = box.xyxy[0].cpu().numpy()
            
            detection = {
                'class_id': cls_id,
                'class_name': self.bolt_class_names.get(cls_id, 'unknown'),
                'bbox': xyxy,
                'conf': conf,
                'center': [(xyxy[0] + xyxy[2]) / 2, (xyxy[1] + xyxy[3]) / 2]
            }
            
            if cls_id in [0, 1]:  # ë³¼íŠ¸
                bolt_detections.append(detection)
            elif cls_id in [2, 3, 4, 5, 6, 7]:  # í”„ë ˆì„
                frame_detections.append(detection)
        
        # 2~7ë²ˆ í”„ë ˆì„ì´ ì—†ìœ¼ë©´ ìŠ¤í‚µ
        if len(frame_detections) == 0:
            self._save_visualization(
                img, img_path, [], vis_dir, idx, 
                'skipped', gt_label, None, frame_detections
            )
            return {
                'image_path': img_path,
                'status': 'skipped',
                'message': 'No frame detection (class 2-7)',
                'bolt_count': len(bolt_detections),
                'frame_count': len(frame_detections)
            }
        
        # ê° í”„ë ˆì„ ì˜ì—­ ë‚´ì˜ ë³¼íŠ¸ ì°¾ê¸°
        valid_bolts = []
        for frame in frame_detections:
            frame_bbox = frame['bbox']
            frame_cls = frame['class_id']
            
            # ì´ í”„ë ˆì„ ë‚´ì˜ ë³¼íŠ¸ë“¤
            bolts_in_frame = []
            for bolt in bolt_detections:
                cx, cy = bolt['center']
                if (frame_bbox[0] <= cx <= frame_bbox[2] and 
                    frame_bbox[1] <= cy <= frame_bbox[3]):
                    bolts_in_frame.append(bolt)
            
            # í”„ë ˆì„ ë‚´ì˜ ëª¨ë“  ë³¼íŠ¸ë¥¼ ì–‘ë¶ˆëŸ‰ íŒë‹¨ì— ì‚¬ìš©
            valid_bolts.extend(bolts_in_frame)
        
        # ë³¼íŠ¸ê°€ ì—†ìœ¼ë©´ ë¶ˆëŸ‰
        if len(valid_bolts) == 0:
            self._save_visualization(
                img, img_path, [], vis_dir, idx, 
                'defect', gt_label, None, frame_detections
            )
            return {
                'image_path': img_path,
                'status': 'defect',
                'reason': 'no_bolts_in_frame',
                'final_prediction': 'defect'
            }
        
        # ê° ë³¼íŠ¸ë¥¼ DINOv2ë¡œ ë¶„ë¥˜
        bolt_results = []
        crop_info = []
        
        for bolt_idx, bolt in enumerate(valid_bolts):
            bbox = bolt['bbox']
            x1, y1, x2, y2 = map(int, bbox)
            cropped = img[y1:y2, x1:x2]
            
            # í¬ë¡­ ì´ë¯¸ì§€ ì €ì¥
            crop_filename = f"{idx:04d}_bolt_{bolt_idx}.jpg"
            crop_path = crops_dir / crop_filename
            cv2.imwrite(str(crop_path), cropped)
            
            result = self._classify_with_dino(cropped, 'bolt')
            
            bolt_results.append({
                'bbox': bbox.tolist(),
                'yolo_class': bolt['class_name'],
                'yolo_conf': bolt['conf'],
                'pred_class': result['pred_class'],
                'confidence': result['confidence'],
                'is_defect': result['is_defect'],
                'defect_confidence': result['defect_confidence'],
                'num_classes': result['num_classes'],
                'crop_path': str(crop_path)
            })
            
            # ë¼ë²¨ ìƒì„± (2-class ë˜ëŠ” 4-classì— ë”°ë¼)
            num_classes = result['num_classes']
            if num_classes == 4:
                class_names = ['frontside_good', 'frontside_bad', 'side_good', 'side_bad']
                class_name = class_names[result['pred_class']] if result['pred_class'] < len(class_names) else str(result['pred_class'])
                label = f"Bolt: {class_name} ({result['confidence'][result['pred_class']]:.2f})"
            else:
                label = f"Bolt: {'Bad' if result['is_defect'] else 'Good'} ({result['confidence'][result['pred_class']]:.2f})"
            
            crop_info.append({
                'bbox': bbox,
                'label': label,
                'color': (0, 0, 255) if result['is_defect'] else (0, 255, 0)
            })
        
        # Voting ë°©ì‹ìœ¼ë¡œ ìµœì¢… íŒì •
        if self.voting_method == 'hard':
            final_pred = self._hard_voting_bolt(bolt_results)
        else:  # soft
            final_pred = self._soft_voting_bolt(bolt_results)
        
        # ì‹œê°í™” ì €ì¥
        self._save_visualization(
            img, img_path, crop_info, vis_dir, idx, 
            final_pred, gt_label, bolt_results, frame_detections
        )
        
        return {
            'image_path': img_path,
            'status': 'processed',
            'mode': 'bolt',
            'bolt_count': len(valid_bolts),
            'bolt_results': bolt_results,
            'final_prediction': final_pred
        }
    
    def _process_frontdoor_obb(self, img, img_path, obbs, crops_dir, vis_dir, idx, gt_label):
        """í”„ë¡ íŠ¸ë„ì–´ OBB ì²˜ë¦¬"""
        img_h, img_w = img.shape[:2]
        
        # í´ë˜ìŠ¤ë³„ ê²€ì¶œ ê²°ê³¼ ì •ë¦¬
        detections = {'high': [], 'mid': [], 'low': []}
        
        # ë¹ˆ OBB ì²˜ë¦¬
        if len(obbs) == 0:
            self._save_visualization_obb(
                img, img_path, [], vis_dir, idx, 
                'skipped', gt_label, None, None
            )
            return {
                'image_path': img_path,
                'status': 'skipped',
                'message': 'No OBB detections',
                'detections': {k: 0 for k in detections.keys()}
            }
        
        for obb in obbs:
            try:
                cls_id = int(obb.cls[0])
                conf = float(obb.conf[0])
                # OBB í˜•ì‹: xywhr (center_x, center_y, width, height, rotation)
                xywhr = obb.xywhr[0].cpu().numpy()
                if len(xywhr) < 5:
                    continue
                cx, cy, w, h, angle = xywhr[:5]
            
                # ì •ê·œí™”ëœ ì¢Œí‘œë¥¼ ì ˆëŒ€ ì¢Œí‘œë¡œ ë³€í™˜ (xywhrëŠ” ì •ê·œí™”ëœ ì¢Œí‘œë¼ê³  ê°€ì •)
                # ë§Œì•½ ì´ë¯¸ ì ˆëŒ€ ì¢Œí‘œë¼ë©´ ë³€í™˜í•˜ì§€ ì•ŠìŒ (w, hê°€ ì´ë¯¸ì§€ í¬ê¸°ë³´ë‹¤ í¬ë©´ ì ˆëŒ€ ì¢Œí‘œ)
                if w > 1.0 or h > 1.0:
                    # ì´ë¯¸ ì ˆëŒ€ ì¢Œí‘œ
                    cx_abs, cy_abs, w_abs, h_abs = cx, cy, w, h
                else:
                    # ì •ê·œí™”ëœ ì¢Œí‘œë¥¼ ì ˆëŒ€ ì¢Œí‘œë¡œ ë³€í™˜
                    cx_abs = cx * img_w
                    cy_abs = cy * img_h
                    w_abs = w * img_w
                    h_abs = h * img_h
                
                class_name = self.yolo_model.names[cls_id].lower()
                if class_name in detections:
                    detections[class_name].append({
                        'cx': cx_abs,
                        'cy': cy_abs,
                        'w': w_abs,
                        'h': h_abs,
                        'angle': angle,
                        'conf': conf
                    })
            except Exception as e:
                print(f"âš ï¸  OBB ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ (ì´ë¯¸ì§€: {os.path.basename(img_path)}): {e}")
                continue
        
        # ì¡°ê±´ í™•ì¸: high/mid/low ê° 1ê°œì”© OR high/low ê° 1ê°œì”©
        has_all_three = (len(detections['high']) == 1 and 
                        len(detections['mid']) == 1 and 
                        len(detections['low']) == 1)
        has_high_low = (len(detections['high']) == 1 and 
                       len(detections['low']) == 1 and 
                       len(detections['mid']) == 0)
        
        if not (has_all_three or has_high_low):
            # ì‹œê°í™” (ê²€ì¶œ ì‹¤íŒ¨)
            self._save_visualization_obb(
                img, img_path, [], vis_dir, idx, 
                'skipped', gt_label, None, None
            )
            return {
                'image_path': img_path,
                'status': 'skipped',
                'message': 'Detection condition not met',
                'detections': {k: len(v) for k, v in detections.items()}
            }
        
        # ê° ë¶€ìœ„ë³„ í¬ë¡­ ë° ë¶„ë¥˜
        part_results = {}
        parts_to_process = ['high', 'mid', 'low'] if has_all_three else ['high', 'low']
        crop_info = []
        
        for part in parts_to_process:
            if len(detections[part]) > 0:
                det = detections[part][0]
                cx, cy, w, h, angle = det['cx'], det['cy'], det['w'], det['h'], det['angle']
                
                # íšŒì „ëœ ê°ì²´ crop (ë„ì–´ ëª¨ë“œ: part ì •ë³´ ì „ë‹¬)
                cropped = crop_rotated_object(img, cx, cy, w, h, angle, part=part)
                if cropped is None:
                    continue
                
                # í¬ë¡­ ì´ë¯¸ì§€ ì €ì¥
                crop_filename = f"{idx:04d}_{part}.jpg"
                crop_path = crops_dir / crop_filename
                cv2.imwrite(str(crop_path), cropped)
                
                # DINOv2 ë¶„ë¥˜
                result = self._classify_with_dino(cropped, part)
                
                part_results[part] = {
                    'cx': float(cx),
                    'cy': float(cy),
                    'w': float(w),
                    'h': float(h),
                    'angle': float(angle),
                    'yolo_conf': det['conf'],
                    'pred_class': result['pred_class'],
                    'confidence': result['confidence'],
                    'is_defect': result['is_defect'],
                    'defect_confidence': result['defect_confidence'],
                    'num_classes': result['num_classes'],
                    'crop_path': str(crop_path)
                }
                
                # ë¼ë²¨ ìƒì„±
                num_classes = result['num_classes']
                if num_classes == 5:
                    # 5-class ëª¨ë“œ (ë„ì–´): good, shipping_seal, no_seal, work_seal, tape_seal
                    class_names = ['good', 'shipping_seal', 'no_seal', 'work_seal', 'tape_seal']
                    class_name = class_names[result['pred_class']] if result['pred_class'] < len(class_names) else str(result['pred_class'])
                    label = f"{part}: {class_name} ({result['confidence'][result['pred_class']]:.2f})"
                elif num_classes == 4:
                    # 4-class ëª¨ë“œ (ë³¼íŠ¸): frontside_good, frontside_bad, side_good, side_bad
                    class_names = ['frontside_good', 'frontside_bad', 'side_good', 'side_bad']
                    class_name = class_names[result['pred_class']] if result['pred_class'] < len(class_names) else str(result['pred_class'])
                    label = f"{part}: {class_name} ({result['confidence'][result['pred_class']]:.2f})"
                else:
                    # 2-class ëª¨ë“œ
                    label = f"{part}: {'Bad' if result['is_defect'] else 'Good'} ({result['confidence'][result['pred_class']]:.2f})"
                
                crop_info.append({
                    'cx': cx,
                    'cy': cy,
                    'w': w,
                    'h': h,
                    'angle': angle,
                    'label': label,
                    'color': (0, 0, 255) if result['is_defect'] else (0, 255, 0)
                })
        
        # Voting
        if self.voting_method == 'hard':
            final_pred = self._hard_voting(part_results)
        else:  # soft
            final_pred = self._soft_voting(part_results)
        
        # ì‹œê°í™” ì €ì¥
        self._save_visualization_obb(
            img, img_path, crop_info, vis_dir, idx, 
            final_pred, gt_label, part_results, None
        )
        
        return {
            'image_path': img_path,
            'status': 'processed',
            'mode': 'frontdoor',
            'obb_mode': True,
            'parts': part_results,
            'final_prediction': final_pred,
            'voting_method': self.voting_method
        }
    
    def _process_bolt_obb(self, img, img_path, obbs, crops_dir, vis_dir, idx, gt_label):
        """ë³¼íŠ¸ OBB ì²˜ë¦¬"""
        img_h, img_w = img.shape[:2]
        
        # í´ë˜ìŠ¤ë³„ ê²€ì¶œ ê²°ê³¼ ì •ë¦¬
        bolt_detections = []  # 0, 1ë²ˆ í´ë˜ìŠ¤ (ë³¼íŠ¸)
        frame_detections = []  # 2~7ë²ˆ í´ë˜ìŠ¤ (í”„ë ˆì„)
        
        # ë¹ˆ OBB ì²˜ë¦¬
        if len(obbs) == 0:
            self._save_visualization_obb(
                img, img_path, [], vis_dir, idx, 
                'skipped', gt_label, None
            )
            return {
                'image_path': img_path,
                'status': 'skipped',
                'message': 'No OBB detections',
                'bolt_count': 0,
                'frame_count': 0
            }
        
        for obb in obbs:
            try:
                cls_id = int(obb.cls[0])
                conf = float(obb.conf[0])
                xywhr = obb.xywhr[0].cpu().numpy()
                if len(xywhr) < 5:
                    continue
                cx, cy, w, h, angle = xywhr[:5]
                
                # ì •ê·œí™”ëœ ì¢Œí‘œë¥¼ ì ˆëŒ€ ì¢Œí‘œë¡œ ë³€í™˜ (xywhrëŠ” ì •ê·œí™”ëœ ì¢Œí‘œë¼ê³  ê°€ì •)
                # ë§Œì•½ ì´ë¯¸ ì ˆëŒ€ ì¢Œí‘œë¼ë©´ ë³€í™˜í•˜ì§€ ì•ŠìŒ (w, hê°€ ì´ë¯¸ì§€ í¬ê¸°ë³´ë‹¤ í¬ë©´ ì ˆëŒ€ ì¢Œí‘œ)
                if w > 1.0 or h > 1.0:
                    # ì´ë¯¸ ì ˆëŒ€ ì¢Œí‘œ
                    cx_abs, cy_abs, w_abs, h_abs = cx, cy, w, h
                else:
                    # ì •ê·œí™”ëœ ì¢Œí‘œë¥¼ ì ˆëŒ€ ì¢Œí‘œë¡œ ë³€í™˜
                    cx_abs = cx * img_w
                    cy_abs = cy * img_h
                    w_abs = w * img_w
                    h_abs = h * img_h
            
                detection = {
                    'class_id': cls_id,
                    'class_name': self.bolt_class_names.get(cls_id, 'unknown'),
                    'cx': cx_abs,
                    'cy': cy_abs,
                    'w': w_abs,
                    'h': h_abs,
                    'angle': angle,
                    'conf': conf,
                    'center': [cx_abs, cy_abs]
                }
                
                if cls_id in [0, 1]:  # ë³¼íŠ¸
                    bolt_detections.append(detection)
                elif cls_id in [2, 3, 4, 5, 6, 7]:  # í”„ë ˆì„
                    frame_detections.append(detection)
            except Exception as e:
                print(f"âš ï¸  OBB ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ (ì´ë¯¸ì§€: {os.path.basename(img_path)}): {e}")
                continue
        
        # 2~7ë²ˆ í”„ë ˆì„ì´ ì—†ìœ¼ë©´ ìŠ¤í‚µ
        if len(frame_detections) == 0:
            self._save_visualization_obb(
                img, img_path, [], vis_dir, idx, 
                'skipped', gt_label, None, frame_detections
            )
            return {
                'image_path': img_path,
                'status': 'skipped',
                'message': 'No frame detection (class 2-7)',
                'bolt_count': len(bolt_detections),
                'frame_count': len(frame_detections)
            }
        
        # ê° í”„ë ˆì„ ì˜ì—­ ë‚´ì˜ ë³¼íŠ¸ ì°¾ê¸°
        valid_bolts = []
        for frame in frame_detections:
            frame_cx, frame_cy = frame['cx'], frame['cy']
            frame_w, frame_h = frame['w'], frame['h']
            frame_angle = frame['angle']
            frame_cls = frame['class_id']
            
            # ì´ í”„ë ˆì„ ë‚´ì˜ ë³¼íŠ¸ë“¤ (íšŒì „ëœ í”„ë ˆì„ ë‚´ë¶€ í™•ì¸)
            bolts_in_frame = []
            for bolt in bolt_detections:
                bolt_cx, bolt_cy = bolt['center']
                # íšŒì „ëœ í”„ë ˆì„ ë‚´ë¶€ì— ë³¼íŠ¸ê°€ ìˆëŠ”ì§€ í™•ì¸
                if point_in_rotated_box(bolt_cx, bolt_cy, frame_cx, frame_cy, 
                                        frame_w, frame_h, frame_angle):
                    bolts_in_frame.append(bolt)
            
            # í”„ë ˆì„ ë‚´ì˜ ëª¨ë“  ë³¼íŠ¸ë¥¼ ì–‘ë¶ˆëŸ‰ íŒë‹¨ì— ì‚¬ìš©
            valid_bolts.extend(bolts_in_frame)
        
        # ë³¼íŠ¸ê°€ ì—†ìœ¼ë©´ ë¶ˆëŸ‰
        if len(valid_bolts) == 0:
            self._save_visualization_obb(
                img, img_path, [], vis_dir, idx, 
                'defect', gt_label, None, frame_detections
            )
            return {
                'image_path': img_path,
                'status': 'defect',
                'reason': 'no_bolts_in_frame',
                'final_prediction': 'defect'
            }
        
        # ê° ë³¼íŠ¸ë¥¼ DINOv2ë¡œ ë¶„ë¥˜
        bolt_results = []
        crop_info = []
        
        for bolt_idx, bolt in enumerate(valid_bolts):
            cx, cy, w, h, angle = bolt['cx'], bolt['cy'], bolt['w'], bolt['h'], bolt['angle']
            
            # íšŒì „ëœ ê°ì²´ crop
            cropped = crop_rotated_object(img, cx, cy, w, h, angle)
            if cropped is None:
                continue
            
            # í¬ë¡­ ì´ë¯¸ì§€ ì €ì¥
            crop_filename = f"{idx:04d}_bolt_{bolt_idx}.jpg"
            crop_path = crops_dir / crop_filename
            cv2.imwrite(str(crop_path), cropped)
            
            result = self._classify_with_dino(cropped, 'bolt')
            
            bolt_results.append({
                'cx': float(cx),
                'cy': float(cy),
                'w': float(w),
                'h': float(h),
                'angle': float(angle),
                'yolo_class': bolt['class_name'],
                'yolo_conf': bolt['conf'],
                'pred_class': result['pred_class'],
                'confidence': result['confidence'],
                'is_defect': result['is_defect'],
                'defect_confidence': result['defect_confidence'],
                'num_classes': result['num_classes'],
                'crop_path': str(crop_path)
            })
            
            # ë¼ë²¨ ìƒì„± (2-class ë˜ëŠ” 4-classì— ë”°ë¼)
            num_classes = result['num_classes']
            if num_classes == 4:
                class_names = ['frontside_good', 'frontside_bad', 'side_good', 'side_bad']
                class_name = class_names[result['pred_class']] if result['pred_class'] < len(class_names) else str(result['pred_class'])
                label = f"Bolt: {class_name} ({result['confidence'][result['pred_class']]:.2f})"
            else:
                label = f"Bolt: {'Bad' if result['is_defect'] else 'Good'} ({result['confidence'][result['pred_class']]:.2f})"
            
            crop_info.append({
                'cx': cx,
                'cy': cy,
                'w': w,
                'h': h,
                'angle': angle,
                'label': label,
                'color': (0, 0, 255) if result['is_defect'] else (0, 255, 0)
            })
        
        # Voting ë°©ì‹ìœ¼ë¡œ ìµœì¢… íŒì •
        if self.voting_method == 'hard':
            final_pred = self._hard_voting_bolt(bolt_results)
        else:  # soft
            final_pred = self._soft_voting_bolt(bolt_results)
        
        # ì‹œê°í™” ì €ì¥
        self._save_visualization_obb(
            img, img_path, crop_info, vis_dir, idx, 
            final_pred, gt_label, bolt_results, frame_detections
        )
        
        return {
            'image_path': img_path,
            'status': 'processed',
            'mode': 'bolt',
            'obb_mode': True,
            'bolt_count': len(valid_bolts),
            'bolt_results': bolt_results,
            'final_prediction': final_pred
        }
    
    def _save_visualization(self, img, img_path, crop_info, vis_dir, idx, 
                           prediction, gt_label, detail_results, frame_detections=None):
        """ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥"""
        vis_img = img.copy()
        
        # í”„ë ˆì„ ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        if frame_detections:
            for frame in frame_detections:
                bbox = frame['bbox']
                class_name = frame['class_name']
                conf = frame['conf']
                x1, y1, x2, y2 = map(int, bbox)
                # í”„ë ˆì„ì€ íŒŒë€ìƒ‰ìœ¼ë¡œ í‘œì‹œ
                cv2.rectangle(vis_img, (x1, y1), (x2, y2), (255, 0, 0), 2)
                # í”„ë ˆì„ ë¼ë²¨
                frame_label = f"{class_name} ({conf:.2f})"
                label_size, _ = cv2.getTextSize(frame_label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)
                cv2.rectangle(vis_img, (x1, y1 - label_size[1] - 10), 
                             (x1 + label_size[0], y1), (255, 0, 0), -1)
                cv2.putText(vis_img, frame_label, (x1, y1 - 5), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
        
        # ë³¼íŠ¸ ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        for crop in crop_info:
            bbox = crop['bbox']
            label = crop['label']
            color = crop['color']
            
            x1, y1, x2, y2 = map(int, bbox)
            cv2.rectangle(vis_img, (x1, y1), (x2, y2), color, 2)
            
            # ë¼ë²¨ ë°°ê²½
            label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)
            cv2.rectangle(vis_img, (x1, y1 - label_size[1] - 10), 
                         (x1 + label_size[0], y1), color, -1)
            cv2.putText(vis_img, label, (x1, y1 - 5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
        
        # ì˜¤ë¥¸ìª½ ìƒë‹¨ì— ê²°ê³¼ í‘œì‹œ
        h, w = vis_img.shape[:2]
        
        # GT vs Prediction ë¹„êµ
        if gt_label is not None:
            gt_text = "GT: Good" if gt_label == 0 else "GT: Bad"
            pred_text = f"Pred: {prediction.capitalize()}"
            
            # ì •ë‹µ ì—¬ë¶€ íŒë‹¨
            pred_label = 1 if prediction == 'defect' else 0
            is_correct = (gt_label == pred_label)
            result_symbol = "âœ“" if is_correct else "âœ—"
            result_color = (0, 255, 0) if is_correct else (0, 0, 255)
            
            # ë°°ê²½ ì‚¬ê°í˜•
            cv2.rectangle(vis_img, (w - 250, 10), (w - 10, 110), (0, 0, 0), -1)
            cv2.rectangle(vis_img, (w - 250, 10), (w - 10, 110), (255, 255, 255), 2)
            
            # í…ìŠ¤íŠ¸
            cv2.putText(vis_img, gt_text, (w - 240, 40), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            cv2.putText(vis_img, pred_text, (w - 240, 70), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            cv2.putText(vis_img, result_symbol, (w - 240, 100), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, result_color, 3)
        else:
            # GT ì—†ëŠ” ê²½ìš°
            pred_text = f"Pred: {prediction.capitalize()}"
            cv2.rectangle(vis_img, (w - 250, 10), (w - 10, 60), (0, 0, 0), -1)
            cv2.rectangle(vis_img, (w - 250, 10), (w - 10, 60), (255, 255, 255), 2)
            cv2.putText(vis_img, pred_text, (w - 240, 40), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        # ì €ì¥
        vis_filename = f"{idx:04d}_vis.jpg"
        vis_path = vis_dir / vis_filename
        cv2.imwrite(str(vis_path), vis_img)
    
    def _save_visualization_obb(self, img, img_path, crop_info, vis_dir, idx, 
                                prediction, gt_label, detail_results, frame_detections=None):
        """OBB ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥"""
        vis_img = img.copy()
        
        # í”„ë ˆì„ íšŒì „ëœ ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        if frame_detections:
            for frame in frame_detections:
                cx = frame['cx']
                cy = frame['cy']
                w = frame['w']
                h = frame['h']
                angle = frame['angle']
                class_name = frame['class_name']
                conf = frame['conf']
                
                # íšŒì „ëœ í”„ë ˆì„ ë°•ìŠ¤ì˜ ëª¨ì„œë¦¬ ê³„ì‚°
                corners = compute_rotated_box_corners(cx, cy, w, h, angle)
                corners_int = np.array(corners, dtype=np.int32)
                
                # ë‹¤ê°í˜• ê·¸ë¦¬ê¸° (í”„ë ˆì„ì€ íŒŒë€ìƒ‰)
                cv2.polylines(vis_img, [corners_int], isClosed=True, color=(255, 0, 0), thickness=2)
                
                # í”„ë ˆì„ ë¼ë²¨
                frame_label = f"{class_name} ({conf:.2f})"
                x1, y1 = int(corners[0][0]), int(corners[0][1])
                label_size, _ = cv2.getTextSize(frame_label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)
                cv2.rectangle(vis_img, (x1, y1 - label_size[1] - 10), 
                             (x1 + label_size[0], y1), (255, 0, 0), -1)
                cv2.putText(vis_img, frame_label, (x1, y1 - 5), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
        
        # ë³¼íŠ¸ íšŒì „ëœ ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        for crop in crop_info:
            cx = crop['cx']
            cy = crop['cy']
            w = crop['w']
            h = crop['h']
            angle = crop['angle']
            label = crop['label']
            color = crop['color']
            
            # íšŒì „ëœ ë°•ìŠ¤ì˜ ëª¨ì„œë¦¬ ê³„ì‚°
            corners = compute_rotated_box_corners(cx, cy, w, h, angle)
            corners_int = np.array(corners, dtype=np.int32)
            
            # ë‹¤ê°í˜• ê·¸ë¦¬ê¸°
            cv2.polylines(vis_img, [corners_int], isClosed=True, color=color, thickness=2)
            
            # ë¼ë²¨ ë°°ê²½ (ì²« ë²ˆì§¸ ëª¨ì„œë¦¬ ìœ„ì—)
            x1, y1 = int(corners[0][0]), int(corners[0][1])
            label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)
            cv2.rectangle(vis_img, (x1, y1 - label_size[1] - 10), 
                         (x1 + label_size[0], y1), color, -1)
            cv2.putText(vis_img, label, (x1, y1 - 5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
        
        # ì˜¤ë¥¸ìª½ ìƒë‹¨ì— ê²°ê³¼ í‘œì‹œ
        h, w = vis_img.shape[:2]
        
        # GT vs Prediction ë¹„êµ
        if gt_label is not None:
            gt_text = "GT: Good" if gt_label == 0 else "GT: Bad"
            pred_text = f"Pred: {prediction.capitalize()}"
            
            # ì •ë‹µ ì—¬ë¶€ íŒë‹¨
            pred_label = 1 if prediction == 'defect' else 0
            is_correct = (gt_label == pred_label)
            result_symbol = "âœ“" if is_correct else "âœ—"
            result_color = (0, 255, 0) if is_correct else (0, 0, 255)
            
            # ë°°ê²½ ì‚¬ê°í˜•
            cv2.rectangle(vis_img, (w - 250, 10), (w - 10, 110), (0, 0, 0), -1)
            cv2.rectangle(vis_img, (w - 250, 10), (w - 10, 110), (255, 255, 255), 2)
            
            # í…ìŠ¤íŠ¸
            cv2.putText(vis_img, gt_text, (w - 240, 40), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            cv2.putText(vis_img, pred_text, (w - 240, 70), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            cv2.putText(vis_img, result_symbol, (w - 240, 100), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, result_color, 3)
        else:
            # GT ì—†ëŠ” ê²½ìš°
            pred_text = f"Pred: {prediction.capitalize()}"
            cv2.rectangle(vis_img, (w - 250, 10), (w - 10, 60), (0, 0, 0), -1)
            cv2.rectangle(vis_img, (w - 250, 10), (w - 10, 60), (255, 255, 255), 2)
            cv2.putText(vis_img, pred_text, (w - 240, 40), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        # ì €ì¥
        vis_filename = f"{idx:04d}_vis.jpg"
        vis_path = vis_dir / vis_filename
        cv2.imwrite(str(vis_path), vis_img)
    
    def _classify_with_dino(self, cropped_img, part):
        """DINOv2ë¡œ í¬ë¡­ëœ ì´ë¯¸ì§€ ë¶„ë¥˜"""
        num_classes = self.dino_num_classes.get(part, 2)
        
        if cropped_img.size == 0:
            # ë¹ˆ ì´ë¯¸ì§€ëŠ” ë¶ˆëŸ‰ìœ¼ë¡œ
            if num_classes == 5:
                confidence = [0.0, 0.0, 0.0, 0.0, 1.0]  # í´ë˜ìŠ¤ 4ì— ë†’ì€ confidence
                pred_class = 4
                is_defect = True
                defect_confidence = 1.0
            elif num_classes == 4:
                confidence = [0.0, 0.0, 0.0, 1.0]  # í´ë˜ìŠ¤ 3ì— ë†’ì€ confidence
                pred_class = 3
                is_defect = True
                defect_confidence = 1.0
            else:
                confidence = [0.0, 1.0]
                pred_class = 1
                is_defect = True
                defect_confidence = 1.0
            return {
                'pred_class': pred_class,
                'confidence': confidence,
                'is_defect': is_defect,
                'defect_confidence': defect_confidence,
                'num_classes': num_classes
            }
        
        # BGR to RGB
        cropped_rgb = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2RGB)
        pil_img = Image.fromarray(cropped_rgb)
        
        # ì „ì²˜ë¦¬
        img_tensor = self.transform(pil_img).unsqueeze(0).to(self.device)
        
        # ì¶”ë¡ 
        with torch.no_grad():
            outputs = self.dino_models[part](img_tensor)
            probs = torch.softmax(outputs, dim=1)
            pred_class = torch.argmax(probs, dim=1).item()
            confidence = probs[0].cpu().numpy().tolist()
        
        # ì–‘ë¶ˆëŸ‰ íŒì •
        if num_classes == 5:
            # 5-class ëª¨ë“œ (ë„ì–´): 0=ì–‘í’ˆ, 1,2,3,4=ë¶ˆëŸ‰
            is_defect = (pred_class != 0)
            # ë¶ˆëŸ‰ í´ë˜ìŠ¤ë“¤ì˜ confidence í•©ê³„ ê³„ì‚° (ì†Œí”„íŠ¸ ë³´íŒ…ìš©)
            defect_confidence = sum(confidence[1:5]) if len(confidence) >= 5 else sum(confidence[1:]) if len(confidence) > 1 else 0.0
        elif num_classes == 4:
            # 4-class ëª¨ë“œ (ë³¼íŠ¸): 0=ì–‘í’ˆ, 1,2,3=ë¶ˆëŸ‰
            is_defect = (pred_class != 0)
            # ë¶ˆëŸ‰ í´ë˜ìŠ¤ë“¤ì˜ confidence í•©ê³„ ê³„ì‚° (ì†Œí”„íŠ¸ ë³´íŒ…ìš©)
            defect_confidence = sum(confidence[1:4]) if len(confidence) >= 4 else confidence[1] if len(confidence) >= 2 else 0.0
        else:
            # 2-class ëª¨ë“œ: 0=ì–‘í’ˆ, 1=ë¶ˆëŸ‰
            is_defect = (pred_class == 1)
            defect_confidence = confidence[1] if len(confidence) >= 2 else 0.0
        
        return {
            'pred_class': pred_class,
            'confidence': confidence,
            'is_defect': is_defect,
            'defect_confidence': defect_confidence,
            'num_classes': num_classes
        }
    
    def _hard_voting(self, part_results):
        """Hard Voting: í•˜ë‚˜ë¼ë„ ë¶ˆëŸ‰ì´ë©´ ë¶ˆëŸ‰"""
        # ê° ë¶€ìœ„ì˜ is_defect í™•ì¸
        has_defect = any(result.get('is_defect', result['pred_class'] != 0) for result in part_results.values())
        return 'defect' if has_defect else 'good'
    
    def _soft_voting(self, part_results):
        """Soft Voting: í‰ê·  confidence"""
        # ê° ë¶€ìœ„ì˜ ë¶ˆëŸ‰ confidence í‰ê· 
        defect_confidences = [result.get('defect_confidence', result['confidence'][1] if len(result['confidence']) >= 2 else 0.0) 
                             for result in part_results.values()]
        avg_defect_conf = sum(defect_confidences) / len(defect_confidences) if len(defect_confidences) > 0 else 0.0
        
        # í‰ê· ì´ 0.5 ì´ìƒì´ë©´ ë¶ˆëŸ‰
        if avg_defect_conf >= 0.5:
            return 'defect'
        else:
            return 'good'
    
    def _hard_voting_bolt(self, bolt_results):
        """Hard Voting for Bolt: í•˜ë‚˜ë¼ë„ ë¶ˆëŸ‰ì´ë©´ ë¶ˆëŸ‰"""
        if len(bolt_results) == 0:
            return 'good'
        
        has_defect = any(b.get('is_defect', b['pred_class'] == 1) for b in bolt_results)
        return 'defect' if has_defect else 'good'
    
    def _soft_voting_bolt(self, bolt_results):
        """Soft Voting for Bolt: í‰ê·  ë¶ˆëŸ‰ confidence"""
        if len(bolt_results) == 0:
            return 'good'
        
        # ê° ë³¼íŠ¸ì˜ ë¶ˆëŸ‰ confidence í‰ê· 
        defect_confidences = [b.get('defect_confidence', b['confidence'][1] if len(b['confidence']) >= 2 else 0.0) 
                             for b in bolt_results]
        avg_defect_conf = sum(defect_confidences) / len(defect_confidences) if len(defect_confidences) > 0 else 0.0
        
        # í‰ê· ì´ 0.5 ì´ìƒì´ë©´ ë¶ˆëŸ‰
        if avg_defect_conf >= 0.5:
            return 'defect'
        else:
            return 'good'
    
    def _save_results(self, results, result_dir):
        """ê²°ê³¼ ì €ì¥"""
        output_file = result_dir / 'results.json'
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        print(f"\nâœ“ ê²°ê³¼ ì €ì¥: {output_file}")
    
    def _plot_confusion_matrix(self, y_true, y_pred, result_dir):
        """Confusion Matrix ìƒì„± ë° ì €ì¥ (ì–‘í’ˆ/ë¶ˆëŸ‰ 2-class)"""
        # Confusion Matrix ê³„ì‚°
        cm = [[0, 0], [0, 0]]  # [[TN, FP], [FN, TP]]
        
        for true, pred in zip(y_true, y_pred):
            cm[true][pred] += 1
        
        # ì‹œê°í™”
        fig, ax = plt.subplots(figsize=(8, 6))
        
        # Heatmap
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                   xticklabels=['Good', 'Defect'],
                   yticklabels=['Good', 'Defect'],
                   ax=ax, cbar_kws={'label': 'Count'})
        
        ax.set_xlabel('Predicted Label', fontsize=12, fontweight='bold')
        ax.set_ylabel('True Label', fontsize=12, fontweight='bold')
        ax.set_title('Confusion Matrix (Good/Defect)', fontsize=14, fontweight='bold')
        
        plt.tight_layout()
        cm_path = result_dir / 'confusion_matrix.png'
        plt.savefig(cm_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ“ Confusion Matrix ì €ì¥: {cm_path}")
        
        # ì •ê·œí™”ëœ Confusion Matrix ìƒì„±
        cm_normalized = [[0.0, 0.0], [0.0, 0.0]]
        total_samples = len(y_true)
        if total_samples > 0:
            for i in range(2):
                row_sum = sum(cm[i])
                if row_sum > 0:
                    for j in range(2):
                        cm_normalized[i][j] = cm[i][j] / row_sum
        
        # ì •ê·œí™”ëœ ë²„ì „ ì‹œê°í™”
        fig, ax = plt.subplots(figsize=(8, 6))
        sns.heatmap(cm_normalized, annot=True, fmt='.3f', cmap='Blues', 
                   xticklabels=['Good', 'Defect'],
                   yticklabels=['Good', 'Defect'],
                   ax=ax, cbar_kws={'label': 'Normalized Count'}, vmin=0, vmax=1)
        
        ax.set_xlabel('Predicted Label', fontsize=12, fontweight='bold')
        ax.set_ylabel('True Label', fontsize=12, fontweight='bold')
        ax.set_title('Normalized Confusion Matrix (Good/Defect)', fontsize=14, fontweight='bold')
        
        plt.tight_layout()
        cm_norm_path = result_dir / 'confusion_matrix_normalized.png'
        plt.savefig(cm_norm_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ“ Normalized Confusion Matrix ì €ì¥: {cm_norm_path}")
        
        # ë©”íŠ¸ë¦­ ê³„ì‚°
        tn, fp, fn, tp = cm[0][0], cm[0][1], cm[1][0], cm[1][1]
        total = tn + fp + fn + tp
        
        accuracy = (tp + tn) / total if total > 0 else 0
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
        
        # ë©”íŠ¸ë¦­ ì €ì¥
        metrics = {
            'confusion_matrix': {
                'TN': int(tn), 'FP': int(fp),
                'FN': int(fn), 'TP': int(tp)
            },
            'metrics': {
                'accuracy': float(accuracy),
                'precision': float(precision),
                'recall': float(recall),
                'f1_score': float(f1)
            }
        }
        
        metrics_path = result_dir / 'metrics.json'
        with open(metrics_path, 'w', encoding='utf-8') as f:
            json.dump(metrics, f, indent=2)
        
        print(f"âœ“ ë©”íŠ¸ë¦­ ì €ì¥: {metrics_path}")
        
        return metrics
    
    def _plot_bolt_class_confusion_matrix(self, y_true_class, y_pred_class, result_dir):
        """ë³¼íŠ¸ 4-class ëª¨ë“œìš© í´ë˜ìŠ¤ë³„ Confusion Matrix ìƒì„± ë° ì €ì¥"""
        num_classes = 4
        class_names = ['frontside_good', 'frontside_bad', 'side_good', 'side_bad']
        
        # Confusion Matrix ê³„ì‚°
        cm = [[0 for _ in range(num_classes)] for _ in range(num_classes)]
        for true, pred in zip(y_true_class, y_pred_class):
            if 0 <= true < num_classes and 0 <= pred < num_classes:
                cm[true][pred] += 1
        
        # ì‹œê°í™”
        fig, ax = plt.subplots(figsize=(10, 8))
        
        cm_np = np.array(cm, dtype=np.int32)
        
        # Heatmap
        sns.heatmap(cm_np, annot=True, fmt='d', cmap='Blues', 
                   xticklabels=class_names,
                   yticklabels=class_names,
                   ax=ax, cbar_kws={'label': 'Count'})
        
        ax.set_xlabel('Predicted Label', fontsize=12, fontweight='bold')
        ax.set_ylabel('True Label', fontsize=12, fontweight='bold')
        ax.set_title('Confusion Matrix (Bolt 4-Class)', fontsize=14, fontweight='bold')
        
        plt.setp(ax.get_xticklabels(), rotation=45, ha='right', rotation_mode='anchor')
        plt.tight_layout()
        cm_path = result_dir / 'confusion_matrix_bolt_4class.png'
        plt.savefig(cm_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ“ Bolt 4-Class Confusion Matrix ì €ì¥: {cm_path}")
        
        # ì •ê·œí™”ëœ Confusion Matrix ìƒì„±
        cm_normalized = [[0.0 for _ in range(num_classes)] for _ in range(num_classes)]
        for i in range(num_classes):
            row_sum = sum(cm[i])
            if row_sum > 0:
                for j in range(num_classes):
                    cm_normalized[i][j] = cm[i][j] / row_sum
        
        # ì •ê·œí™”ëœ ë²„ì „ ì‹œê°í™”
        fig, ax = plt.subplots(figsize=(10, 8))
        cm_norm_np = np.array(cm_normalized, dtype=np.float32)
        
        sns.heatmap(cm_norm_np, annot=True, fmt='.3f', cmap='Blues', 
                   xticklabels=class_names,
                   yticklabels=class_names,
                   ax=ax, cbar_kws={'label': 'Normalized Count'}, vmin=0, vmax=1)
        
        ax.set_xlabel('Predicted Label', fontsize=12, fontweight='bold')
        ax.set_ylabel('True Label', fontsize=12, fontweight='bold')
        ax.set_title('Normalized Confusion Matrix (Bolt 4-Class)', fontsize=14, fontweight='bold')
        
        plt.setp(ax.get_xticklabels(), rotation=45, ha='right', rotation_mode='anchor')
        plt.tight_layout()
        cm_norm_path = result_dir / 'confusion_matrix_bolt_4class_normalized.png'
        plt.savefig(cm_norm_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ“ Bolt 4-Class Normalized Confusion Matrix ì €ì¥: {cm_norm_path}")
        
        # ë©”íŠ¸ë¦­ ê³„ì‚° (ê° í´ë˜ìŠ¤ë³„)
        class_metrics = {}
        for i in range(num_classes):
            tp = cm[i][i]
            fp = sum(cm[j][i] for j in range(num_classes) if j != i)
            fn = sum(cm[i][j] for j in range(num_classes) if j != i)
            tn = sum(cm[j][k] for j in range(num_classes) for k in range(num_classes) if j != i and k != i)
            
            precision = tp / (tp + fp) if (tp + fp) > 0 else 0
            recall = tp / (tp + fn) if (tp + fn) > 0 else 0
            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
            
            class_metrics[class_names[i]] = {
                'precision': float(precision),
                'recall': float(recall),
                'f1_score': float(f1)
            }
        
        # ì „ì²´ ì •í™•ë„
        total_correct = sum(cm[i][i] for i in range(num_classes))
        total_samples = len(y_true_class)
        overall_accuracy = total_correct / total_samples if total_samples > 0 else 0
        
        # ë©”íŠ¸ë¦­ ì €ì¥
        metrics = {
            'confusion_matrix_4class': cm,
            'class_metrics': class_metrics,
            'overall_accuracy': float(overall_accuracy)
        }
        
        metrics_path = result_dir / 'metrics_bolt_4class.json'
        with open(metrics_path, 'w', encoding='utf-8') as f:
            json.dump(metrics, f, indent=2)
        
        print(f"âœ“ Bolt 4-Class ë©”íŠ¸ë¦­ ì €ì¥: {metrics_path}")
        
        return metrics
    
    def _plot_door_class_confusion_matrix(self, y_true_class, y_pred_class, result_dir):
        """ë„ì–´ 5-class ëª¨ë“œìš© í´ë˜ìŠ¤ë³„ Confusion Matrix ìƒì„± ë° ì €ì¥"""
        num_classes = 5
        class_names = ['good', 'shipping_seal', 'no_seal', 'work_seal', 'tape_seal']
        
        # Confusion Matrix ê³„ì‚°
        cm = [[0 for _ in range(num_classes)] for _ in range(num_classes)]
        for true, pred in zip(y_true_class, y_pred_class):
            if 0 <= true < num_classes and 0 <= pred < num_classes:
                cm[true][pred] += 1
        
        # ì‹œê°í™”
        fig, ax = plt.subplots(figsize=(12, 10))
        
        cm_np = np.array(cm, dtype=np.int32)
        
        # Heatmap
        sns.heatmap(cm_np, annot=True, fmt='d', cmap='Blues', 
                   xticklabels=class_names,
                   yticklabels=class_names,
                   ax=ax, cbar_kws={'label': 'Count'})
        
        ax.set_xlabel('Predicted Label', fontsize=12, fontweight='bold')
        ax.set_ylabel('True Label', fontsize=12, fontweight='bold')
        ax.set_title('Confusion Matrix (Door 5-Class)', fontsize=14, fontweight='bold')
        
        plt.setp(ax.get_xticklabels(), rotation=45, ha='right', rotation_mode='anchor')
        plt.tight_layout()
        cm_path = result_dir / 'confusion_matrix_door_5class.png'
        plt.savefig(cm_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ“ Door 5-Class Confusion Matrix ì €ì¥: {cm_path}")
        
        # ì •ê·œí™”ëœ Confusion Matrix ìƒì„±
        cm_normalized = [[0.0 for _ in range(num_classes)] for _ in range(num_classes)]
        for i in range(num_classes):
            row_sum = sum(cm[i])
            if row_sum > 0:
                for j in range(num_classes):
                    cm_normalized[i][j] = cm[i][j] / row_sum
        
        # ì •ê·œí™”ëœ ë²„ì „ ì‹œê°í™”
        fig, ax = plt.subplots(figsize=(12, 10))
        cm_norm_np = np.array(cm_normalized, dtype=np.float32)
        
        sns.heatmap(cm_norm_np, annot=True, fmt='.3f', cmap='Blues', 
                   xticklabels=class_names,
                   yticklabels=class_names,
                   ax=ax, cbar_kws={'label': 'Normalized Count'}, vmin=0, vmax=1)
        
        ax.set_xlabel('Predicted Label', fontsize=12, fontweight='bold')
        ax.set_ylabel('True Label', fontsize=12, fontweight='bold')
        ax.set_title('Normalized Confusion Matrix (Door 5-Class)', fontsize=14, fontweight='bold')
        
        plt.setp(ax.get_xticklabels(), rotation=45, ha='right', rotation_mode='anchor')
        plt.tight_layout()
        cm_norm_path = result_dir / 'confusion_matrix_door_5class_normalized.png'
        plt.savefig(cm_norm_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ“ Door 5-Class Normalized Confusion Matrix ì €ì¥: {cm_norm_path}")
        
        # ë©”íŠ¸ë¦­ ê³„ì‚° (ê° í´ë˜ìŠ¤ë³„)
        class_metrics = {}
        for i in range(num_classes):
            tp = cm[i][i]
            fp = sum(cm[j][i] for j in range(num_classes) if j != i)
            fn = sum(cm[i][j] for j in range(num_classes) if j != i)
            tn = sum(cm[j][k] for j in range(num_classes) for k in range(num_classes) if j != i and k != i)
            
            precision = tp / (tp + fp) if (tp + fp) > 0 else 0
            recall = tp / (tp + fn) if (tp + fn) > 0 else 0
            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
            
            class_metrics[class_names[i]] = {
                'precision': float(precision),
                'recall': float(recall),
                'f1_score': float(f1)
            }
        
        # ì „ì²´ ì •í™•ë„
        total_correct = sum(cm[i][i] for i in range(num_classes))
        total_samples = len(y_true_class)
        overall_accuracy = total_correct / total_samples if total_samples > 0 else 0
        
        # ë©”íŠ¸ë¦­ ì €ì¥
        metrics = {
            'confusion_matrix_5class': cm,
            'class_metrics': class_metrics,
            'overall_accuracy': float(overall_accuracy)
        }
        
        metrics_path = result_dir / 'metrics_door_5class.json'
        with open(metrics_path, 'w', encoding='utf-8') as f:
            json.dump(metrics, f, indent=2, ensure_ascii=False)
        
        print(f"âœ“ Door 5-Class ë©”íŠ¸ë¦­ ì €ì¥: {metrics_path}")
        
        return metrics
    
    def _print_statistics(self, results, y_true, y_pred):
        """í†µê³„ ì¶œë ¥"""
        print(f"\n{'='*60}")
        print("ğŸ“Š ì²˜ë¦¬ í†µê³„")
        print(f"{'='*60}")
        
        # ìƒíƒœë³„ í†µê³„
        status_counts = {}
        for result in results:
            status = result.get('status', 'unknown')
            status_counts[status] = status_counts.get(status, 0) + 1
        
        print("\n[ì²˜ë¦¬ ìƒíƒœë³„ í†µê³„]")
        for status, count in sorted(status_counts.items()):
            print(f"  - {status}: {count}ê°œ")
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        if len(y_true) > 0 and len(y_pred) > 0:
            cm = [[0, 0], [0, 0]]  # [[TN, FP], [FN, TP]]
            for true, pred in zip(y_true, y_pred):
                cm[true][pred] += 1
            
            tn, fp, fn, tp = cm[0][0], cm[0][1], cm[1][0], cm[1][1]
            total = tn + fp + fn + tp
            
            accuracy = (tp + tn) / total if total > 0 else 0
            precision = tp / (tp + fp) if (tp + fp) > 0 else 0
            recall = tp / (tp + fn) if (tp + fn) > 0 else 0
            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
            
            print(f"\n[ì„±ëŠ¥ ë©”íŠ¸ë¦­]")
            print(f"  - Accuracy:  {accuracy:.4f} ({tp + tn}/{total})")
            print(f"  - Precision: {precision:.4f} ({tp}/{tp + fp})")
            print(f"  - Recall:    {recall:.4f} ({tp}/{tp + fn})")
            print(f"  - F1 Score:  {f1:.4f}")
            print(f"\n[Confusion Matrix]")
            print(f"  True Negative (TN):  {tn}")
            print(f"  False Positive (FP): {fp}")
            print(f"  False Negative (FN): {fn}")
            print(f"  True Positive (TP):  {tp}")
        else:
            print("\n[ì„±ëŠ¥ ë©”íŠ¸ë¦­]")
            print("  GT ë¼ë²¨ì´ ì—†ì–´ ë©”íŠ¸ë¦­ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        print(f"\n{'='*60}\n")


def parse_args():
    parser = argparse.ArgumentParser(description="YOLO + DINOv2 í…ŒìŠ¤íŠ¸ íŒŒì´í”„ë¼ì¸")
    parser.add_argument("--config", required=True, type=str, help="ëª¨ë¸ ê²½ë¡œë“¤ì´ ë“¤ì–´ìˆëŠ” YAML íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--txt", required=True, type=str, help="ì²˜ë¦¬í•  ì´ë¯¸ì§€ ê²½ë¡œ ëª©ë¡ì´ ë‹´ê¸´ txt íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--mode", required=True, choices=["frontdoor", "door", "bolt"], help="ì‹¤í–‰ ëª¨ë“œ (doorëŠ” frontdoorì˜ ë³„ì¹­)")
    parser.add_argument("--voting", default="hard", choices=["soft", "hard"], help="ë³´íŒ… ë°©ì‹ (ê¸°ë³¸ê°’: hard)")
    parser.add_argument("--project", default="pipeline_test", type=str, help="runs í•˜ìœ„ ê²°ê³¼ í´ë”ëª… prefix")
    parser.add_argument("--conf", default=0.25, type=float, help="YOLO ì‹ ë¢°ë„ ì„ê³„ê°’")
    parser.add_argument("--device", default="cuda", type=str, help="ë””ë°”ì´ìŠ¤ (cuda|cpu)")
    parser.add_argument("--obb", action="store_true", help="OBB(Oriented Bounding Box) ëª¨ë“œ ì‚¬ìš©")
    return parser.parse_args()


def load_models_from_yaml(config_path, mode):
    with open(config_path, "r", encoding="utf-8") as f:
        cfg = yaml.safe_load(f)

    # YAMLì€ ëª¨ë¸ ê²½ë¡œë§Œ í¬í•¨í•œë‹¤ê³  ê°€ì •
    yolo_model_path = cfg.get("yolo_model") or cfg.get("yolo") or cfg.get("yolo_model_path")
    if yolo_model_path is None:
        raise ValueError("YAMLì— 'yolo_model' ê²½ë¡œê°€ í•„ìš”í•©ë‹ˆë‹¤.")

    # 'door'ë¥¼ 'frontdoor'ë¡œ ì •ê·œí™”
    if mode.lower() == "door":
        mode = "frontdoor"

    dino_models = {}
    if mode == "frontdoor":
        # ì˜ˆìƒ í‚¤: high, mid, low
        for key in ["high", "mid", "low"]:
            if key not in cfg:
                raise ValueError("frontdoor ëª¨ë“œëŠ” YAMLì— 'high', 'mid', 'low' í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            dino_models[key] = cfg[key]
    else:
        # bolt ëª¨ë“œ: bolt ë‹¨ì¼ í‚¤
        bolt_path = cfg.get("bolt")
        if bolt_path is None:
            raise ValueError("bolt ëª¨ë“œëŠ” YAMLì— 'bolt' í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        dino_models["bolt"] = bolt_path

    return yolo_model_path, dino_models


def main():
    args = parse_args()

    # YAMLì—ì„œ ê²½ë¡œë“¤ ë¡œë“œ
    yolo_model_path, dino_models = load_models_from_yaml(args.config, args.mode)

    # íŒŒì´í”„ë¼ì¸ ìƒì„±
    pipeline = YOLODINOPipeline(
        mode=args.mode,
        yolo_model_path=yolo_model_path,
        dino_models=dino_models,
        device=args.device,
        conf_threshold=args.conf,
        voting_method=args.voting,
        project_name=args.project,
        use_obb=args.obb,
    )

    # ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬
    pipeline.process_image_list(args.txt)


if __name__ == "__main__":
    main()